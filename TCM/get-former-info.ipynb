{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get former info for TCM\n",
    "1. This file get the former info for TCM.\n",
    "2. Former info are the number of added, modified and removed for text(sentences), wikilinks and url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as ddf\n",
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import collections\n",
    "import string\n",
    "import mwparserfromhell\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetdir = '../../tcm-columns-add-main/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process revision text\n",
    "process revision text to extract:\n",
    "1. sentences: wiki content splitted into sentences\n",
    "2. wikilinks: internal links that direct to another wiki page\n",
    "3. urls: external links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_text= ddf.read_parquet(os.path.join(parquetdir,'revision.text')).compute()\n",
    "parent_ids  = ddf.read_parquet(os.path.join(parquetdir,'revision.parentid')).compute()\n",
    "df = revision_text.join(parent_ids.drop(columns={'dir0'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_revision_text(text):\n",
    "    parsed_wikicode = mwparserfromhell.parse(text)\n",
    "    # wikilinks\n",
    "    wikilinks = parsed_wikicode.filter_wikilinks()\n",
    "    # url\n",
    "    urls = parsed_wikicode.filter_external_links()\n",
    "    # revision text\n",
    "    content = parsed_wikicode.strip_code()\n",
    "    content = content.replace('\\n','.')\n",
    "    # remove the space before dot\n",
    "    content = re.sub(r'\\s+([.](?:\\s|$))', r'\\1',content)\n",
    "    # content = re.split(r'(?<=[^A-Z].[.?])+[ ]*(?=[A-Z=<])',content)\n",
    "    content = re.split(r'(?<=.[.?])+[ ]*(?=[A-Za-z=<])',content)\n",
    "    content = [i.translate(str.maketrans('', '', string.punctuation)) for i in content]\n",
    "    extracted_wikilinks = [str(i) for i in wikilinks]\n",
    "    extracted_urls = [str(i) for i in urls]\n",
    "    extracted_text = [\" \".join(i.split()) for i in content if i]\n",
    "    return pd.Series([extracted_wikilinks,extracted_urls,extracted_text],index=['wikilinks','url','text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['wikilinks','url','text']] = ddf.from_pandas(df,npartitions=4*multiprocessing.cpu_count()).\\\n",
    "map_partitions(lambda d: d['revision.text'].apply(process_revision_text)).compute(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[['text']]\n",
    "text.astype(str).to_parquet('../../intermediate-result/TCM/text-info')\n",
    "wikilink = df[['wikilinks']]\n",
    "wikilink.astype(str).to_parquet('../../intermediate-result/TCM/wikilink-info')\n",
    "url = df[['url']]\n",
    "url.astype(str).to_parquet('../../intermediate-result/TCM/url-info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find added and removed info\n",
    "compare the text, wikilinks and url of each revision with its parent revision. Then use collections to get the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_added_removed(d,col):\n",
    "    curr_id = d.name\n",
    "    prev_id = d['revision.parentid']\n",
    "    curr_content = collections.Counter(df.loc[curr_id][col])\n",
    "    prev_content = collections.Counter()\n",
    "\n",
    "    if prev_id in df.index:\n",
    "        prev_content = collections.Counter(df.loc[prev_id][col])\n",
    "\n",
    "    added = curr_content - prev_content\n",
    "    removed = prev_content - curr_content\n",
    "\n",
    "    return pd.Series([added,removed],index=[col+'.added',col+'.removed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text.added','text.removed']] = df.apply(find_added_removed,args=('text',),axis=1)\n",
    "df[['wikilinks.added','wikilinks.removed']] = df.apply(find_added_removed,args=('wikilinks',),axis=1)\n",
    "df[['url.added','url.removed']] = df.apply(find_added_removed,args=('url',),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = df[['text.added','text.removed','wikilinks.added','wikilinks.removed','url.added','url.removed']]\n",
    "\n",
    "final_df = ddf.from_pandas(final,npartitions=4*multiprocessing.cpu_count())\n",
    "\n",
    "final_df.to_parquet('../../intermediate-result/TCM/TCM-added-removed-info', object_encoding='json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find modified info\n",
    "For each revision, compare added and removed info. If added and removed are similar (sequence match > 0.8), then classify this pair as a modified pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_list(d):\n",
    "    res = []\n",
    "    for item in d:\n",
    "        res.append(item)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_modification(df,col):\n",
    "    added = df[col + '.added']\n",
    "    removed = df[col + '.removed']\n",
    "    \n",
    "    if (len(added) == 0) & (len(removed) == 0):\n",
    "        return [[],[],[]]\n",
    "    elif len(added) == 0:\n",
    "        return [[],[],convert_dict_to_list(df[col + '.removed'])]\n",
    "    elif len(removed) == 0:\n",
    "        return [convert_dict_to_list(df[col + '.added']),[],[]]\n",
    "    else:\n",
    "        added_list = convert_dict_to_list(added)\n",
    "        removed_list = convert_dict_to_list(removed)\n",
    "        matched_indexes = []\n",
    "        similar_pairs = []\n",
    "        for i in range(len(added_list)):\n",
    "            val = added_list[i]\n",
    "            sim = list(map(lambda x: similar(x,val),removed_list))\n",
    "            if len(sim) > 0:\n",
    "                max_sim = max(sim)\n",
    "                max_index = sim.index(max(sim))\n",
    "                if (max_sim > 0.8) and (max_index not in matched_indexes):\n",
    "                    similar_pairs.append([i,max_index])\n",
    "                    matched_indexes.append(max_index)\n",
    "                    \n",
    "        add_index = [item[0] for item in similar_pairs]\n",
    "        removed_index = [item[1] for item in similar_pairs]\n",
    "        add_matched = [added_list[i] for i in add_index]\n",
    "        removed_matched = [removed_list[i] for i in removed_index]\n",
    "        \n",
    "        modified_res = [{removed_list[item[1]]:added_list[item[0]]} for item in similar_pairs]\n",
    "        added_res = list(set(added_list)^set(add_matched))\n",
    "        removed_res = list(set(removed_list)^set(removed_matched))\n",
    "        \n",
    "        return [added_res,modified_res,removed_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "final[['new.wikilinks.added','new.wikilinks.modified','new.wikilinks.removed']] = \\\n",
    "final.apply(lambda d: find_modification(d,'wikilinks'),axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[['new.url.added','new.url.modified','new.url.removed']] = \\\n",
    "final.apply(lambda d: find_modification(d,'url'),axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[['new.text.added','new.text.modified','new.text.removed']] = \\\n",
    "final.apply(lambda d: find_modification(d,'text'),axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = final[['new.text.added','new.text.modified','new.text.removed','new.wikilinks.added','new.wikilinks.modified',\\\n",
    "             'new.wikilinks.removed','new.url.added','new.url.modified','new.url.removed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = ddf.from_pandas(res,chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_parquet('../../intermediate-result/TCM/TCM-added-modified-removed',object_encoding='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute former info\n",
    "Compute the number of added, modified and remove for each revision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len(df):\n",
    "    df['text.added'] = len(df['new.text.added'])\n",
    "    df['text.modified'] = len(df['new.text.modified'])\n",
    "    df['text.removed'] = len(df['new.text.removed'])\n",
    "    df['wikilinks.added'] = len(df['new.wikilinks.added'])\n",
    "    df['wikilinks.modified'] = len(df['new.wikilinks.modified'])\n",
    "    df['wikilinks.removed'] = len(df['new.wikilinks.removed'])\n",
    "    df['url.added'] = len(df['new.url.added'])\n",
    "    df['url.modified'] = len(df['new.url.modified'])\n",
    "    df['url.removed'] = len(df['new.url.removed'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = res.apply(get_len,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = fin[['text.added','text.modified','text.removed','wikilinks.added','wikilinks.modified','wikilinks.removed',\\\n",
    "           'url.added','url.modified','url.removed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = ddf.from_pandas(fin,chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df.to_parquet('../../intermediate-result/TCM/TCM-former-info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
